{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNZQmalB0GbuP1gp9FvxtzB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u9oFaeWDSkOP","executionInfo":{"status":"ok","timestamp":1713882403981,"user_tz":-330,"elapsed":1735,"user":{"displayName":"Shakti Shankar Karmakar","userId":"18233247661154444629"}},"outputId":"ca9f00d7-9fda-464e-f856-a6b1fbf751cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n","Downloading breast-cancer-wisconsin-data.zip to /content\n","  0% 0.00/48.6k [00:00<?, ?B/s]\n","100% 48.6k/48.6k [00:00<00:00, 49.8MB/s]\n","Archive:  breast-cancer-wisconsin-data.zip\n","  inflating: data.csv                \n"]}],"source":["import os\n","os.environ['KAGGLE_CONFIG_DIR'] ='/content'\n","!kaggle datasets download -d uciml/breast-cancer-wisconsin-data\n","!unzip \\*.zip && rm *.zip"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","\n","# Step 1: Load Data\n","data = pd.read_csv('/content/data.csv')\n","\n","# Assuming 'diagnosis' is the target variable\n","X = data[['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n","          'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean']]\n","y = data['diagnosis']  # Target variable\n","\n","# Step 2: Splitting the dataset into the Training set and Test set\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Step 3: Calculate similarity matrix\n","def calculate_similarity_matrix(X):\n","    n_samples = X.shape[0]\n","    similarity_matrix = np.zeros((n_samples, n_samples))\n","    for i in range(n_samples):\n","        for j in range(n_samples):\n","            similarity_matrix[i][j] = np.dot(X[i], X[j]) / (np.linalg.norm(X[i]) * np.linalg.norm(X[j]))\n","    return similarity_matrix\n","\n","# Step 4: Define adaptive threshold\n","def calculate_adaptive_threshold(similarity_matrix):\n","    return np.mean(similarity_matrix)\n","\n","# Step 5: Compute weighted distances\n","def compute_weighted_distances(x_test, X_train, similarity_matrix):\n","    weighted_distances = []\n","    for x_train in X_train:\n","        similarity = np.dot(x_test, x_train) / (np.linalg.norm(x_test) * np.linalg.norm(x_train))\n","        weighted_distance = np.linalg.norm(x_test - x_train) / similarity\n","        weighted_distances.append(weighted_distance)\n","    return weighted_distances\n","\n","# Step 6: Classify test instances\n","def classify_test_instances(X_train, y_train, X_test, k, similarity_matrix, adaptive_threshold):\n","    y_pred = []\n","    for x_test in X_test:\n","        weighted_distances = compute_weighted_distances(x_test, X_train, similarity_matrix)\n","        nearest_indices = np.argsort(weighted_distances)[:k]\n","        nearest_labels = [y_train[i] for i in nearest_indices]\n","        count_M = nearest_labels.count('M')\n","        count_B = nearest_labels.count('B')\n","        predicted_label = 'M' if count_M > count_B else 'B'\n","        y_pred.append(predicted_label)\n","    return y_pred\n","\n","# Step 7: Apply EAKNN algorithm\n","similarity_matrix = calculate_similarity_matrix(X_train.to_numpy())\n","adaptive_threshold = calculate_adaptive_threshold(similarity_matrix)\n","k = 5  # Number of neighbors\n","y_pred = classify_test_instances(X_train.to_numpy(), y_train.to_numpy(), X_test.to_numpy(), k, similarity_matrix, adaptive_threshold)\n","\n","# Step 8: Evaluate performance\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1 Score:\", f1)\n","\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"STwa5yDrWgmy","executionInfo":{"status":"ok","timestamp":1713882533948,"user_tz":-330,"elapsed":13053,"user":{"displayName":"Shakti Shankar Karmakar","userId":"18233247661154444629"}},"outputId":"68a32141-0396-4dfd-d5bd-1d9db53e0d1e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9385964912280702\n","Precision: 0.9409048938134812\n","Recall: 0.9385964912280702\n","F1 Score: 0.937745598564312\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           B       0.92      0.99      0.95        71\n","           M       0.97      0.86      0.91        43\n","\n","    accuracy                           0.94       114\n","   macro avg       0.95      0.92      0.93       114\n","weighted avg       0.94      0.94      0.94       114\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"c75dfx0MW9lN"},"execution_count":null,"outputs":[]}]}
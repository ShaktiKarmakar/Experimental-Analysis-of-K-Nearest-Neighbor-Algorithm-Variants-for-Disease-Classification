{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOR7FvQpbzrruSntvfBnG3+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z7beNLUG2Fg1","executionInfo":{"status":"ok","timestamp":1713892456563,"user_tz":-330,"elapsed":2100,"user":{"displayName":"Shakti Shankar Karmakar","userId":"18233247661154444629"}},"outputId":"1d23e0df-be77-420a-f195-7a2fd0117642"},"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n","Downloading cancer-data.zip to /content\n","  0% 0.00/48.6k [00:00<?, ?B/s]\n","100% 48.6k/48.6k [00:00<00:00, 10.2MB/s]\n","Archive:  cancer-data.zip\n","  inflating: Cancer_Data.csv         \n"]}],"source":["import os\n","os.environ['KAGGLE_CONFIG_DIR'] ='/content'\n","!kaggle datasets download -d erdemtaha/cancer-data\n","!unzip \\*.zip && rm *.zip"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import AgglomerativeClustering\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","\n","# Step 1: Load Data\n","data = pd.read_csv('/content/Cancer_Data.csv')  # Replace '/path/to/your/dataset.csv' with the actual path\n","\n","# Step 2: Prepare Data\n","X = data[['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n","          'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean']]\n","y = data['diagnosis']  # Target variable\n","\n","# Step 3: Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Step 4: Standardize the features\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Step 5: Cluster the training data using Hierarchical Clustering\n","n_clusters = 5  # Number of clusters\n","hierarchical_clustering = AgglomerativeClustering(n_clusters=n_clusters)\n","cluster_labels_train = hierarchical_clustering.fit_predict(X_train_scaled)\n","cluster_centers = []\n","for i in range(n_clusters):\n","    cluster_center = X_train_scaled[cluster_labels_train == i].mean(axis=0)\n","    cluster_centers.append(cluster_center)\n","\n","# Step 6: Apply KNN within each cluster\n","k = 5  # Number of neighbors\n","knn_models = []\n","for i in range(n_clusters):\n","    # Find data points and labels within the cluster\n","    cluster_indices = np.where(cluster_labels_train == i)[0]\n","    X_cluster = X_train_scaled[cluster_indices]\n","    y_cluster = y_train.iloc[cluster_indices]\n","\n","    # Train KNN model for the cluster\n","    knn_model = KNeighborsClassifier(n_neighbors=k)\n","    knn_model.fit(X_cluster, y_cluster)\n","    knn_models.append(knn_model)\n","\n","# Step 7: Make predictions\n","y_pred = []\n","for x_test_point in X_test_scaled:\n","    # Find the nearest cluster center\n","    nearest_cluster_index = np.argmin(np.linalg.norm(cluster_centers - x_test_point, axis=1))\n","\n","    # Get indices of data points in the nearest cluster\n","    nearest_cluster_indices = np.where(cluster_labels_train == nearest_cluster_index)[0]\n","\n","    # Extract data points and labels within the nearest cluster\n","    X_nearest_cluster = X_train_scaled[nearest_cluster_indices]\n","    y_nearest_cluster = y_train.iloc[nearest_cluster_indices]\n","\n","    # Apply KNN to data points within the nearest cluster\n","    knn_model = knn_models[nearest_cluster_index]\n","    predicted_class = knn_model.predict([x_test_point])[0]\n","    y_pred.append(predicted_class)\n","\n","# Step 8: Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","\n","# Display evaluation metrics\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1 Score:\", f1)\n","\n","# Display classification report\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-wo5PxUR7xL7","executionInfo":{"status":"ok","timestamp":1713892524087,"user_tz":-330,"elapsed":420,"user":{"displayName":"Shakti Shankar Karmakar","userId":"18233247661154444629"}},"outputId":"b03ca0a0-e5c9-4008-e168-b578c372485f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9035087719298246\n","Precision: 0.9088250930356195\n","Recall: 0.9035087719298246\n","F1 Score: 0.9043988410104431\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           B       0.95      0.89      0.92        71\n","           M       0.83      0.93      0.88        43\n","\n","    accuracy                           0.90       114\n","   macro avg       0.89      0.91      0.90       114\n","weighted avg       0.91      0.90      0.90       114\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"uQS087sF856e"},"execution_count":null,"outputs":[]}]}
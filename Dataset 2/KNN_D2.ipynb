{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNcwf7HrhPjp2XCF8vLW/IO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hSjpEG3EE7-k","executionInfo":{"status":"ok","timestamp":1713862340967,"user_tz":-330,"elapsed":1530,"user":{"displayName":"Shakti Shankar Karmakar","userId":"18233247661154444629"}},"outputId":"86e7fa47-8c92-45a3-fca8-1a847deba528"},"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n","Downloading brain-stroke-dataset.zip to /content\n","  0% 0.00/47.2k [00:00<?, ?B/s]\n","100% 47.2k/47.2k [00:00<00:00, 70.2MB/s]\n"]}],"source":["import os\n","os.environ['KAGGLE_CONFIG_DIR'] ='/content'\n","!kaggle datasets download -d jillanisofttech/brain-stroke-dataset\n"]},{"cell_type":"code","source":["!unzip \\*.zip && rm *.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v3TvZbn9Fc3a","executionInfo":{"status":"ok","timestamp":1713862355613,"user_tz":-330,"elapsed":747,"user":{"displayName":"Shakti Shankar Karmakar","userId":"18233247661154444629"}},"outputId":"6809d769-f47e-4aa5-9b3f-6956700bae4a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  brain-stroke-dataset.zip\n","  inflating: brain_stroke.csv        \n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","class KNNEnsemble:\n","    def __init__(self, n_estimators=10, n_neighbors=5):\n","        self.n_estimators = n_estimators\n","        self.n_neighbors = n_neighbors\n","        self.models = []\n","\n","    def fit(self, X, y):\n","        for _ in range(self.n_estimators):\n","            # Create a KNN classifier\n","            knn = KNeighborsClassifier(n_neighbors=self.n_neighbors)\n","            # Train the KNN classifier on the full training data\n","            knn.fit(X, y)\n","            self.models.append(knn)\n","        return self\n","\n","    def predict(self, X):\n","        # Make predictions with each model\n","        predictions = np.array([model.predict(X) for model in self.models])\n","        # Aggregate predictions using majority voting\n","        y_pred = np.apply_along_axis(lambda x: np.argmax(np.bincount(x)), axis=0, arr=predictions)\n","        return y_pred\n","\n","\n","# Load the dataset (Replace 'your_dataset.csv' with your actual dataset file)\n","data = pd.read_csv('/content/brain_stroke.csv')\n","\n","# Handle missing values if any\n","\n","# Convert categorical variables to numerical using one-hot encoding\n","data = pd.get_dummies(data, columns=['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'])\n","\n","# Split the dataset into features and target variable\n","X = data.drop(columns=['stroke'])  # Features\n","y = data['stroke']  # Target variable\n","\n","# Split the dataset into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Perform feature scaling\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Initialize and train the KNN ensemble classifier\n","knn_ensemble = KNNEnsemble(n_estimators=10, n_neighbors=5)\n","knn_ensemble.fit(X_train_scaled, y_train)\n","\n","# Make predictions on the test set using the KNN ensemble classifier\n","ensemble_predictions = knn_ensemble.predict(X_test_scaled)\n","\n","# Calculate evaluation metrics for the ensemble classifier\n","ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n","ensemble_precision = precision_score(y_test, ensemble_predictions)\n","ensemble_recall = recall_score(y_test, ensemble_predictions)\n","ensemble_f1 = f1_score(y_test, ensemble_predictions)\n","\n","# Print the evaluation metrics\n","print(\"Ensemble Accuracy:\", ensemble_accuracy)\n","print(\"Ensemble Precision:\", ensemble_precision)\n","print(\"Ensemble Recall:\", ensemble_recall)\n","print(\"Ensemble F1-score:\", ensemble_f1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cWkW6ECKIZsD","executionInfo":{"status":"ok","timestamp":1713862423801,"user_tz":-330,"elapsed":5673,"user":{"displayName":"Shakti Shankar Karmakar","userId":"18233247661154444629"}},"outputId":"f400de18-9935-4983-e24b-e79913bfe94c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Ensemble Accuracy: 0.9428284854563691\n","Ensemble Precision: 0.2\n","Ensemble Recall: 0.018518518518518517\n","Ensemble F1-score: 0.03389830508474576\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"0WqHSeAwIobc"},"execution_count":null,"outputs":[]}]}